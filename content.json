[{"title":"星际穿越","date":"2018-06-10T12:20:29.000Z","path":"2018/06/10/星际穿越/","text":"诺兰大神14年的电影，上周末又拿出来再刷一遍，看得我好几次起鸡皮疙瘩，非常感动。看完觉得从另一个角度理解了时间，空间，虫洞，黑洞，同时诺兰又在电影里加上了人性和爱。 老物理学家说他害怕的是时间。是的，他已经解出了那个方程式，知道一切无望。只有B计划才是唯一能将人类种族繁衍下去的办法。他直到临终前都一直在说Do not go gentle into that good night 。诗里的night或许指的是地球上人类的灭亡，所以他即使已经算出了方程式，也希望可以找到一些方法拯救留在这个星球上的人类。所以他说自己害怕的是时间。在临终前，告诉了墨菲真相，他希望墨菲可以Do not go gentle into that good night,或许她可以拯救留在这个星球上的人类。 不要温和地走入那良夜 不要温和地走入那良夜，老年人应该燃烧并对着日暮呼喊；怒斥、怒斥那光明的微灭。 尽管聪明人临终时知道黑暗真确，是因为他们的话语没有迸射闪电，他们并不温和地走入那良夜。 好人，当最后一浪涌过，号呼他们脆弱的功业本可以很光辉地起舞于绿色的海湾，也怒斥、怒斥那光明的微灭。 狂放的人碰见并歌唱过太阳的飞越，意识到，太晚了，他们曾使它在途中哀叹，他们也并不温和地走入那良夜。 沉肃的人，临死时用目眩的视觉看到瞎眼也能像流星般闪耀而欣欢，也怒斥、怒斥那光明的微灭。 而您呀，我的父亲，身处高度的悲切，请用您的热泪诅咒、祝福我，我祈愿。不要温和地走入那良夜，怒斥、怒斥那光明的微灭。 上面是这首诗的一个翻译版本。这首诗原本是诗人写给临危的父亲的，诺兰将这首诗作为电影的主题，是写给临危的地球和人类的。Do not go gentle into that good night像是老教授对人类的呐喊，而库珀和墨菲则像是在rage against the dying of the light 最后，男主马修麦康纳和安妮海瑟薇的新片《宁静》最近曝光了预告片，期待一波~","tags":[{"name":"诺兰","slug":"诺兰","permalink":"http://yoursite.com/tags/诺兰/"}]},{"title":"Git以及TortoiseGit安装使用","date":"2018-06-10T12:02:12.000Z","path":"2018/06/10/Git使用手册/","text":"1. 下载安装Git-2.8.3-64-bit.exe程序 默认选项一直next即可。 本地初始化git的配置项，设置username和email，使用如下命令： 12git config --global user.name \"abc\"git config --global user.email \"123abc@163.com\" –global 表示全局属性，所有的git项目都会公用这个属性。因为Git是分布式版本控制系统，需要一个用户名和email作为一个标识。 2. 配置ssh key 生成秘钥对 在Git Bash中输入以下命令 ： 1ssh-keygen -t rsa -C &quot;123abc@163.com&quot; 之后可以不用设置密码，按下3个回车键即可。接下来可以去默认路径 C:\\Users\\banana\\.ssh下查看生成的两个文件，分别为 私钥：id_rsa 公钥：id_rsa.pub ​ 添加公钥到远程仓库打开GitHub主页，在Settings–&gt;SSH and GPG keys中，点击New SSH key 按钮； 再打开公钥文件，将其中的字符串完整复制，粘贴到key 中 执行ssh -T git@github.com 命令，查看公钥是否配置成功了，如下图所示则表示成功： 将私钥添加到自己的系统中 使用命令： ssh-add ~/.ssh/id_rsa 添加私钥至系统中，若无效的话，建议采取以下两种方法： 先执行 eval &#39;ssh-agent-s&#39; 再执行 ssh-add ~/.ssh/id_rsa ； 先执行ssh-agent bash --login -i 启动bash，或者说把bash挂到ssh-agent下面，再执行 ssh-add 当看到下图所示结果时，则表示成功了 3. 配置远程仓库 登录github账号，新建一个远程仓库。 在本地建一个与仓库同名的文件夹，在文件夹中打开Git Bash，执行如下命令： 123456789101112echo &quot;# commang&quot; &gt;&gt; README.md新建一个README.md文件，写入“# commang”git init初始化git文件夹，创建master分支和.git文件夹git add README.md将工作区中的README.md文件添加进暂存区git commit -m &quot;first commit&quot;将暂存区的文件提交到master分支上git remote add origin git@github.com:abc/gitTest.git配置远程仓库地址命名为origingit push -u origin master将本地master分支的数据push到远程仓库的master分支上 若没能成功push去服务器的话，可以去检查下本地.git 文件夹下的config 文件，其中的url必须与上述命令中的远程地址相同。 4.安装TortoiseGit-2.6.0.0-64bit.msi文件 下载TortoiseGit和中文语言包 默认选项一直next即可。 创建本地仓库，在文件夹中右键--&gt;Git在这里创建版本库 （我使用的是中文版本），如下图： 不用勾选，直接确定即可。 设置网络和远端 1. 右键--&gt;设置 将本地安装Git的ssh.exe路径地址配置到网络上，如下图： 我的Git是安装在C:\\software\\Git\\路径下 。 2. 将远程仓库的地址粘贴到URL和推送URL 中，如下图： 至此，你已经可以愉快的使用右键进行push和update了，但是会时不时遇到需要输入密码，但是你怎么输都不对的情况。 5. 使用本地Pageant记住你的私钥密码 开始菜单找到TortoiseGit菜单下的puttygen，打开puttygen 选择导入秘钥 选择C:\\Users\\Administrator.ssh目录下的私钥，并输入秘钥密码 选择save private key，将私钥另存为ppk格式的秘钥 开始菜单找到TortoiseGit菜单下的pageant，打开 点击add key，选择ppk秘钥，输入密码 每次开机启动pagent并添加ppk秘钥 点击torise git – settings 设置network—ssh的路径，设置为“C:\\Program Files\\TortoiseGit\\bin\\TortoisePlink.exe” 6. 使用过程遇到的问题 在新文件下拉取远程仓库报错：You asked to pull from the remote ‘origin’, but did not specify:a branch. Because this is not the default configured remotefor your current branch, you must specify a branch on the command line. 找到：.git/config文件 添加如下 123[branch &quot;master&quot;] remote = origin merge = refs/heads/master 在设置git远端地址时，尽量修改远端名称 如果不设置的话，在同一个文件夹下，新建两个文件夹，在这两个文件夹中分别拉取不同仓库的内容时就会报错 当新建了一个空的远程仓库，本地创建了一个关联到远端地址的仓库后，不要尝试拉取，否则会报出Couldn&#39;t find remote ref master错误信息 idea使用Git时，需要配置ssh 设置私钥地址 ​ 设置Git地址和SSH executable 为Native 设置github地址 对于重命名改名字等操作都可以在本地，修改完后添加进版本控制再push到远端仓库即可 对于在第2步中修改了本地远端的名称的操作，如果在idea中拉取代码的话，回报出这个错误： 1234Can&apos;t Update No tracked branch configured for branch master or the branch doesn&apos;t exist. To make your branch track a remote branch call, for example, git branch --set-upstream-to origin/master master (show balloon) 此时，可以执行命令git branch --set-upstream-to origin-repo/master master 意思是使我们在git设置的本地远程名称origin-repo/master追踪远程仓库的master分支 ​ ​","tags":[{"name":"GIT","slug":"GIT","permalink":"http://yoursite.com/tags/GIT/"}]},{"title":"Nginx安装部署web工程","date":"2018-05-30T14:24:24.808Z","path":"2018/05/30/Nginx安装部署web工程/","text":"Nginx安装1. 下载依赖包 如果你的服务器可以连接网络的话可以直接通过命令的方式下载tar包 下载PCRE库 wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.38.tar.gz 下载zlib库 wget http://zlib.net/zlib-1.2.10.tar.gz 下载OpenSSL库 wget https://www.openssl.org/source/openssl-1.0.2o.tar.gz 如果你的服务器无法联网，可以自行去上面的wget命令后面的地址下载对应的tar包文件，ftp路径也可以直接通过浏览器打开，再将他们传到服务器中。 2. 安装依赖包 安装PCRE库 tar -zxvf pcre-8.37.tar.gz 先使用命令解压tar包 cd pcre-8.38 进去解压后的文件目录 ./configure 运行初始化脚本 如果此时你不是用root用户安装，或者希望指定安装根路径，可以使用--prefix=参数来指定安装路径 如：使用./configure --prefix=/home/test/pcre命令来指定将pcre安装到/home/tese/pcre目录下 make 使用make命令尝试编译 make install 编译安装 安装zlib库 tar -zxvf zlib-1.2.10.tar.gz 先使用命令解压tar包 cd zlib-1.2.10 进去解压后的文件目录 ./configure 运行初始化脚本 如果此时你不是用root用户安装，或者希望指定安装根路径，可以使用--prefix=参数来指定安装路径 如：使用./configure --prefix=/home/test/zlib命令来指定将zlib安装到/home/test/zlib目录下 make 使用make命令尝试编译 make install 编译安装 安装OpenSSL库 tar -zxvf openssl-1.0.2o.tar.gz 使用命令解压tar包即可 3. 安装Nginx3.1 安装步骤 先下载Nginx的tar包，我这里选择的是最新的稳定版nginx-1.14.0.tar.gz 跟上面安装依赖包一样，如果你的服务器可以联网的话建议使用wget http://nginx.org/download/nginx-1.14.0.tar.gz命令来下载tar包；如果不能联网的话建议自己通过浏览器访问http地址下载 tar -zxvf nginx-1.14.0.tar.gz 解压Nginx的tar包 cd nginx-1.14.0 进入解压后的目录 ./configure运行初始化脚本 注意：Nginx默认的安装路径是/usr/local/nginx,如果你不是使用root用户的话，就不能使用该路径。这里同样可以使用--prefix=参数来指定安装路径 同时，你可以使用--with-pcre=/home/test/pcre-8.38来指定pcre安装路径 使用--with-zlib=/home/test/zlib来指定zlib的安装路径 make 使用make命令尝试编译 make install 编译安装 cd sbin 进入sbin目录下 ./nginx 启动Nginx 同时可以使用 ./nginx -s reload 重启Nginx 使用./nginx -s stop 关停Nginx 3.2 Nginx常用编译选项 make是用来编译的，它从Makefile中读取指令，然后编译。 make install是用来安装的，它也从Makefile中读取指令，安装到指定的位置。 configure命令是用来检测你的安装平台的目标特征的。它定义了系统的各个方面，包括nginx的被允许使用的连接处理的方法，比如它会检测你是不是有CC或GCC，并不是需要CC或GCC，它是个shell脚本，执行结束时，它会创建一个Makefile文件。nginx的configure命令支持以下参数： --prefix=*path* 定义一个目录，存放服务器上的文件 ，也就是nginx的安装目录。默认使用 /usr/local/nginx。 --sbin-path=*path* 设置nginx的可执行文件的路径，默认为 *prefix*/sbin/nginx. --conf-path=*path* 设置在nginx.conf配置文件的路径。nginx允许使用不同的配置文件启动，通过命令行中的-c选项。默认为*prefix*/conf/nginx.conf. --pid-path=*path* 设置nginx.pid文件，将存储的主进程的进程号。安装完成后，可以随时改变的文件名 ， 在nginx.conf配置文件中使用 PID指令。默认情况下，文件名 为`prefix/logs/nginx.pid`. --error-log-path=*path* 设置主错误，警告，和诊断文件的名称。安装完成后，可以随时改变的文件名 ，在nginx.conf配置文件中 使用 的error_log指令。默认情况下，文件名 为*prefix*/logs/error.log. --http-log-path=*path* 设置主请求的HTTP服务器的日志文件的名称。安装完成后，可以随时改变的文件名 ，在nginx.conf配置文件中 使用 的access_log指令。默认情况下，文件名 为*prefix*/logs/access.log. --user=*name* 设置nginx工作进程的用户。安装完成后，可以随时更改的名称在nginx.conf配置文件中 使用的 user指令。默认的用户名是nobody。 --group=*name* 设置nginx工作进程的用户组。安装完成后，可以随时更改的名称在nginx.conf配置文件中 使用的 user指令。默认的为非特权用户。 --with-select_module --without-select_module 启用或禁用构建一个模块来允许服务器使用select()方法。该模块将自动建立，如果平台不支持的kqueue，epoll，rtsig或/dev/poll。 --with-poll_module --without-poll_module 启用或禁用构建一个模块来允许服务器使用poll()方法。该模块将自动建立，如果平台不支持的kqueue，epoll，rtsig或/dev/poll。 --without-http_gzip_module — 不编译压缩的HTTP服务器的响应模块。编译并运行此模块需要zlib库。 --without-http_rewrite_module 不编译重写模块。编译并运行此模块需要PCRE库支持。 --without-http_proxy_module — 不编译http_proxy模块。 --with-http_ssl_module — 使用https协议模块。默认情况下，该模块没有被构建。建立并运行此模块的OpenSSL库是必需的。 --with-pcre=*path* — 设置PCRE库的源码路径。PCRE库的源码（版本4.4 - 8.30）需要从PCRE网站下载并解压。其余的工作是Nginx的./ configure和make来完成。正则表达式使用在location指令和 ngx_http_rewrite_module 模块中。 --with-pcre-jit —编译PCRE包含“just-in-time compilation”（1.1.12中， pcre_jit指令）。 --with-zlib=*path* —设置的zlib库的源码路径。要下载从 zlib（版本1.1.3 - 1.2.5）的并解压。其余的工作是Nginx的./ configure和make完成。ngx_http_gzip_module模块需要使用zlib 。 --with-cc-opt=*parameters* — 设置额外的参数将被添加到CFLAGS变量。例如,当你在FreeBSD上使用PCRE库时需要使用:--with-cc-opt=&quot;-I /usr/local/include。.如需要需要增加 select()支持的文件数量:--with-cc-opt=&quot;-D FD_SETSIZE=2048&quot;. --with-ld-opt=*parameters* —设置附加的参数，将用于在链接期间。例如，当在FreeBSD下使用该系统的PCRE库,应指定:--with-ld-opt=&quot;-L /usr/local/lib&quot;. 典型实例(下面为了展示需要写在多行，执行时内容需要在同一行) 12345678&gt; ./configure&gt; --sbin-path=/usr/local/nginx/nginx&gt; --conf-path=/usr/local/nginx/nginx.conf&gt; --pid-path=/usr/local/nginx/nginx.pid&gt; --with-http_ssl_module&gt; --with-pcre=../pcre-4.4&gt; --with-zlib=../zlib-1.1.3&gt; 部署web工程1. 关于Nginx配置文件在部署web工程前，我们需要了解Nginx的配置文件。Nginx的配置文件存放在nginx/conf/nginx.conf。我们需要打开这个文件根据自己的web工程需求配置这个文件。 在nginx配置文件中主要分为四部分：main 全局设置，server主机设置，upstream（上游服务器设置，主要为反向代理、负载均衡相关配置）和 location（URL匹配特定位置后的设置） main部分设置的指令将影响其它所有部分的设置；server部分的指令主要用于指定虚拟主机域名、IP和端口；upstream的指令用于设置一系列的后端服务器，设置反向代理及后端服务器的负载均衡；location部分用于匹配网页位置（比如，根目录“/”,“/images”,等等）。他们之间的关系式：server继承main，location继承server；upstream既不会继承指令也不会被继承。它有自己的特殊指令，不需要在其他地方的应用。 先贴一个配置文件，再来按照这个文件进行说明 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114#user nobody;#在配置文件的顶级main部分，worker角色的工作进程的个数，master进程是接收并分配请求给worker处理。这个数值简单一点可以设置为cpu的核数grep ^processor /proc/cpuinfo | wc -l，也是 auto 值，如果开启了ssl和gzip更应该设置成与逻辑CPU数量一样甚至为2倍，可以减少I/O操作。如果nginx服务器还有其它服务，可以考虑适当减少。worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123;#写在events部分。每一个worker进程能并发处理（发起）的最大连接数（包含与客户端或后端被代理服务器间等所有连接数）。nginx作为反向代理服务器，计算公式 最大连接数 = worker_processes * worker_connections/4，所以这里客户端最大连接数是1024，这个可以增到到8192都没关系，看情况而定，但不能超过后面的worker_rlimit_nofile。当nginx作为http服务器时，计算公式里面是除以2。 worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件， 减少用户空间到内核空间的上下文切换。对于普通应用设为 on，如果用来进行下载等应用 磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。 sendfile on; # tcp_nopush on; #长连接超时时间，单位是秒。长连接请求大量小文件的时候，可以减少重建连接的开销， 但假如有大文件上传，65s内没上传完成会导致失败。如果设置时间过长，用户又多，长时 间保持连接会占用大量资源。 keepalive_timeout 65; # gzip压缩功能设置 # 开启gzip压缩输出，减少网络传输 gzip on; #设置允许压缩的页面最小字节数，页面字节数从header头得content-length中进行获取。默认值是20。建议设置成大于1k的字节数，小于1k可能会越压越大 gzip_min_length 1k; #设置系统获取几个单位的缓存用于存储gzip的压缩结果数据流。4 16k代表以16k为单位，安装原始数据大小以16k为单位的4倍申请内存。 gzip_buffers 4 16k; #gzip压缩比，1压缩比最小处理速度最快，9压缩比最大但处理速度最慢(传输快但比较消耗cpu) gzip_comp_level 6; #匹配mime类型进行压缩，无论是否指定,”text/html”类型总是会被压缩的。 gzip_types text/html text/plain text/css text/javascript application/json application/javascript application/x-javascript application/xml; #和http头有关系，会在响应头加个 Vary: Accept-Encoding ，可以让前端的缓存服务器缓存经过gzip压缩的页面，例如，用Squid缓存经过Nginx压缩的数据。。 gzip_vary on; # http_proxy 设置 #允许客户端请求的最大单文件字节数。如果有上传较大文件，请设置它的限制值 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数 client_body_buffer_size 128k; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 75; #连接成功后，与后端服务器两个成功的响应操作之间超时时间(代理接收超时) proxy_read_timeout 75; #设置代理服务器（nginx）从后端realserver读取并保存用户头信息的缓冲区大小，默认 与proxy_buffers大小相同，其实可以将这个指令值设的小一点 proxy_buffer_size 4k; #proxy_buffers缓冲区，nginx针对单个连接缓存来自后端realserver的响应，网页平均 在32k以下的话，这样设置 proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #当缓存被代理的服务器响应到临时文件时，这个选项限制每次写临时文件的大小。 proxy_temp_path（可以在编译的时候）指定写到哪那个目录。。 proxy_temp_file_write_size 64k; #指定将上面的临时文件写到哪那个目录。 proxy_temp_path /usr/local/nginx/proxy_temp 1 2; # 设定负载均衡后台服务器列表 upstream arc &#123; #ip_hash; server 192.168.10.100:8080 max_fails=2 fail_timeout=30s ; server 192.168.10.101:8080 max_fails=2 fail_timeout=30s ; &#125; # 很重要的虚拟主机配置 server &#123; #虚拟主机监听的端口 listen 8001; #服务器名 server_name localhost; #charset utf-8; #access_log logs/host.access.log main; #对 / 所有做负载均衡+反向代理 location / &#123; #定义服务器的默认网站根目录位置。 root html; #定义路径下默认访问的文件名 index index.jsp index.html index.htm; #请求转向arc定义的服务器列表，即反向代理，对应upstream负载均衡器。 proxy_pass http://arc; #下面这几个就这么设置吧 具体的我也不清楚 proxy_redirect off; # 后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; ## 其它虚拟主机，server 指令开始&#125; 2. 部署前端工程将web项目上传到Nginx的安装目录中的html文件夹中。修改nginx.conf配置文件。 遇到的问题 web端不能访问 检查防火墙是否关闭！关闭防火墙：service iptables stop 非root用户报出bind() to 0.0.0.0:80 failed (13:Permission denied)错误 这是由于非root用户启动时，nginx.conf文件中配置的端口为80，而在Linux中只有root用户才能使用1024以下的端口。所以只要讲配置文件中的端口修改为1024以上即可。 参考链接Nginx安装 Nging下部署项目，配置文件修改 nginx服务器安装及配置文件详解","tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"老无所依","date":"2018-05-27T11:40:59.000Z","path":"2018/05/27/老无所依/","text":"天一给我推荐的科恩兄弟系列，反派发型很萌，又很聪明，演员是西班牙人，叫哈维尔巴登。把反派演的很有魅力，天一称之为影史上最难忘的反派之一，其实在我心里最好的反派依旧是小丑。 一直没看懂为什么片名叫老无所依，但是很喜欢这张海报 向来很喜欢红色，这张海报简直大爱 看完电影你就知道为什么我要放这张图了，设计的很棒","tags":[{"name":"科恩兄弟","slug":"科恩兄弟","permalink":"http://yoursite.com/tags/科恩兄弟/"}]},{"title":"关于第一次换工作的面试经验","date":"2018-05-27T10:50:51.227Z","path":"2018/05/27/关于第一次换工作的面试经验/","text":"因为一直想去南方的城市。所以我决定离开恒生去深圳发展，于是在2018年3月份的时候开始计划准备离职，那时候我还在北京。当时已经跟我的主管老大提出离职的意向。离职的流程大概要走一个月左右，在这一个月的时间内，我开始准备一些面试的东西，主要还是java基础这一块。所以从那个时候起，我开始写一些笔记，然后参加一些面试，主要是想通过这种方式，来增加自己的面试经验,了解自己有哪些不足的地方。然后当时恒生也在招人，所以就跟着几个老同事一起面了几个开发。在这里记录一下，我从2018年4月份至2018年5月份，这一个多月的时间里，参加过的所有面试经历，还有碰到的一些的面试题以及我个人对面试这件事情的看法和总结。 先锋支付面试流程先锋支付的面试流程是先参加笔试，笔试之后紧接着参加面试。这也是大多数公司都会采用的一种面试流程。当然也有很多公司追求效率直接让你参加面试。笔试和面试题 内连接，左连接，全连接之间的区别。 chmod 给文件授权和find命令的使用 如何在数据库每一秒钟都有数据写入的时候进行拆表。 spring scope？ 这个问题经常遇到，我在目前工作的这家公司笔试的时候也遇到过。 spring动态代理 实现方式和配置 java的几种加密方式 定时任务的实现方式 final,finally,finalize这三者之间的区别。 策略模式，命令模式与模板模式之间的区别。 灵狮区块链面试流程这家公司是约的电话面试。面试官人很好，面试问到的内容，基本上都是关于java基础然后跟面试官聊的也比较久，双方对彼此都有一个比较好的了解。面试题 java内存模型，堆内存和栈内存的区别。 spring aop使用了什么设计模式? 关于spring aop的考察也是会经常遇到的问题。主要需要了解的就是spring aop的实现方式，它是通过动态代理实现的，然后面试官又会扩展的问道，动态代理有几种实现方式？ socket网络编程 如何实现线程之间的通信。 这里主要是看一下juc包的源码 hashmap的数据结构，以及实现方式。 关于这一块，我有写过它的源码分析文章。 mongodb与传统数据库有什么区别？ 以及mangodb常用的命令这个问题我也遇到过很多次其实问的都不难，是一些比较基础的东西。 关于jpa的了解。 其实这里暴露了我的一个问题。我当时不知道jpa是啥。包括在后来的面试中，一个面试官问我关于orm的理解。其实我也不太清楚，orm是什么东西。所以在面试的时候，关于这些特别基础的常识性的东西，还是需要了解清楚。否则答不上来的话，会让人觉得你比较业余。而我当时，只顾着复习java基础的东西，关于框架这一块学习的不多。之前在公司，都是使用现成的框架，也没有去折腾过jpa，orm 查询sql语句优化。关于sq优化的问题我在很多面试中都遇到过。 左连接，右连接，与内连接之间的区别？ 这个问题我在之前的面试中就已经遇到过。 平时喜欢钻研的技术？ 这个问题其实在很多公司面试的时候都会问到。很多面试官其实就是项目组的技术负责人，然后他们会考察你作为一个开发人员对于技术的热情。所以这个时候，如果你有写过一些，技术博客，或者看过一些源码，或者直接把github账号展现给面试官看的话，会是一个优势。 嘉联支付面试流程嘉联支付的面试流程是先笔试，然后紧接着跟技术负责人聊。笔试和面试题 mybatis分页实现。 这个我之前在恒生的时候已经看过mybatis分页的源代码。这一块主要是通过分页插件拦截器实现的。 springaop原理。 这个问题我在上面遇到过。 对spring mvc和severlet的了解。 关于spring mvc这一块的东西在面试中还是会经常遇到的。因为我之前一直是做后台的开发，所以对前台mvc的东西了解的不多。去找工作面试的话，还是应该要全面一点，至少要了解一些常用的东西。要做到你知道这是一个什么东西，即使你不精通，但是哪怕你写过一个简单的demo。也比直接说，我不知道要强。 单例模式手写。 嘉联支付的笔试要求手写出单例模式。当时我并没有完整的写出来。程序里面忘了加static关键字。 zk分布式锁的实现。 sql去重有哪些方法。 软通动力面试流程软通动力的面试也是先笔试再面试的形式。但是软通动力的面试官真的很不专业。所以不建议大家以后去这种，外包公司去面试，其实对于你刷面试经验并没有太大的帮助。因为你极有可能碰到的是一个非常不靠谱的面试官，他不懂得怎么面试。 笔试和面试题 说一下nginx如何部署。 这个我不会，没答上来。 为什么选用mongodb。 这个问题我当时直接说了一下mangodb，它解决了我们哪些业务场景的问题 查看数据库表用户命令。 这个问题我也没有答上来。 说一下spring MVC 说一下serverlet 说一下java这门语言 当面试官问出这些问题的时候，我其实是比较反感的。首先，面试一定是面试者和公司双方之间的交流。并不是单纯的面试官问面试者问题。所以，对于面试者来说，在一场面试中，他需要从面试官那里充分了解这个公司。所以经常有一些面试官会问，你有些什么想要从我这里获知的。对于面试官来说，他想要知道的是，面试者是否达到了自己这个岗位的要求。 因此当面试官问我怎么看java这门语言的时候。我觉得这种问题除了让面试官秀自己的优越感以外，其他毫无意义。即使我这个问题回答的再好，也并不能体现我开发技能有多好，最多只能体现出我对java这门语言的理解水平。 说一下java并发和多线程。 在回答这一题的时候，我直接说出了一种最简单的实现方式。后来我反思了一下，觉得我说得并不好，因为其实面试官肯定知道这种简单的东西，他希望的是你要答出他的痛点。你需要讲出多线程并发编程的时候，哪些需要注意的事项。这个也是我后来跟一个猎头朋友，还有一个技术负责人聊天的时候，他们给我的一点提示，对我的帮助还是很大的。 关于软通动力面试后的总结在经过了软通动力的面试之后，我自己反思了一下在这场面试中有哪些不足的地方？最后我得到的收获是，第一点对于自己原本就，不是太有兴趣的公司，应该直接不去面试，否则其实是浪费自己的时间。本来我是想通过面试来刷一下自己的面试经验。但是后来我发现，会经常碰到一些不太靠谱的面试官。就像软通动力的这个面试官一样，甚至我答完了面试官的问题之后，我还没有来得及问他一些关于公司的事情，他就直接让我在那里等结果。结果等了一个小时也没有结果。非常不尊重面试者。所以从那之后，任何外包公司的面试我一律不去。第二点是，我没有回答好面试官的说一下XXX系列问题，其实这种问题很难回答，你可以往简单的说，也可以往复杂了说。而且因为这个问题不具体，你不知道面试官的痛点在哪里，很难把这个问题回答的很好。有水平的面试官，他会根据你说出的答案，不断的进行深挖。这样才能体现出你对一个技术点，了解的深度。然而在像软通动力这种外包公司里他们并不注重技术，所以他们的面试官，也不太会注重深挖你的技术。这也是我不建议大家去外包公司面试的原因。因为你有很大的概率会遇到这种麻瓜面试官。 赢时胜面试流程赢时胜的面试流程也是先笔试再面试。面试过程面试官没有问太多技术性的问题，主要是针对笔试题问了些简单的问题，大多数时间聊的还是业务上的事情。因为我之前做的是银行的开发，刚好跟他们的一个现有的项目对口。所以后来赢时胜还是给我发了offer。但是这些大公司都会压你的工资。他们根据工作经验划分出不同的薪资水平，然后根据面试者的面试情况，压低面试者的薪资。他们的这种做法让我觉得很不喜欢，所以虽然后来拿了offer，但是也不是我期望的薪资，当时作为一个保底就先接受了。这里也说一下关于，期望薪资的问题。我之前刷面试经验的时候会去面很多做外包的小公司，然后这些公司出于人力成本的考虑，本来就不会给岗位开出很高的薪资，但是他们会在，招聘信息上把薪资上限的很高。比如三年工作经验以内，给的薪资水平是9k到18k这种。其实他们真正能跟岗位开出的工资也就是9k左右，即使你面试的情况再好，也不可能到18k。当我带着13k期望薪资去面试他们这种岗位的时候，面试官看到你的期望薪资，其实就已经觉得你不太合适了。然后如果他们觉得你的面试情况好的话，肯定会压低你的薪资。 木槿科技面试流程木槿科技的面试时先HR面，人力会跟你大体上聊一些离职原因，之前负责的工作，期望薪资这些。然后是技术负责人面试，他们没有笔试环节。面试题 你对ORM的了解 这里就再次丢脸了，没答出来 zk如何实现分布式锁 这个问题也是之前遇到过的 简述Jdbc的编程过程 这个我之前一直没有自己写过，都是通过使用Mybatis框架来做的这个事情。 Redis的几种数据结构 Hash型数据存储的基本使用命令 这个我之前看过这些简单的命令，但是当时忘了也没答上来。 木槿科技面试总结 在面试木槿的时候遇到过几次很基础，很简单的问题没有答出来。而在这之前我准备的面试方向都是Java基础比较深入的应用。面试了这几家公司发现他们大多数其实问的内容都很简单，根本不会涉及到很深的原理性问题，也不会深挖技术细节。而很多很简单的概念其实我不是很清楚，之前也没关注过这些，所以导致了我很受挫，在面试的时候这种问题答不出来显得很业余。 华锐金融面试流程华锐的面试也是采用先笔试后面试的方式进行面试和笔试题 一个文件里面包含很多个乱序不重复的电话号码，需要在20兆内存的空间内，将这些电话号码进行排序，并重新输出到另一个文件内。 这一题我没有做出来。 java内存模型中，堆内存和栈内存的区别。 垃圾回收算法 如何复制一个对内存中的对象？ 华锐面试的总结其实一开始我笔试题做得并不好，技术面之后，我一度以为自己已经挂了。没想到后来人力资源，和面试官一起讨论了一下，觉得我还可以。紧接着后来就是人力资源给我介绍一下这家公司详细情况。介绍完之后，立马就进行了ceo面。跟ceo聊的很好，然后也了解了这个公司的团队情况，觉得非常厉害，也是我期望的那种工作团队。从面试体验也可以看出来，整个公司团队的，效率和执行力是非常高的。CEO非常尊重工程师，面试结束之后，亲自把我送到了电梯门口。面试是当天上午十点开始的，等结束的时候，快下午1点了。后来我回到家里，下午两三点的时候，人力给我发来录用通知，开出的薪资条件，远远超过了我的期望。可以看出来他们非常的有诚意，也非常尊重工程师文化。通过华锐的面试，给我的感觉是，运气也非常的重要。所以在找工作面试的时候，不要因为，有几家面试失败了，就轻易的看低自己，一定要坚持下去，尽量去一家你想去的公司。如果这家公司从一开始就压榨你的薪资的话，也不用指望你入职之后能有多大的改善","tags":[{"name":"面试总结","slug":"面试总结","permalink":"http://yoursite.com/tags/面试总结/"}]},{"title":"ArrayList源码解析","date":"2018-05-14T12:56:35.266Z","path":"2018/05/14/ArrayList源码分析/","text":"ArrayList源码field1234private static final int DEFAULT_CAPACITY = 10;//默认的数组容量private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;//初始化时加载一个空数组private transient Object[] elementData;//实际用来存储数据的数组private int size;//数组大小 构造器1234public ArrayList() &#123; super(); this.elementData = EMPTY_ELEMENTDATA; &#125; 默认的无参构造器就是简单的将数组引用指向类定义的空数组对象。 123456789public ArrayList(Collection&lt;? extends E&gt; c) &#123; //将集合转换为存储数据的数组 elementData = c.toArray(); size = elementData.length; // c.toArray might (incorrectly) not return Object[] (see 6260652) //若不是Object类型的数组，则将数组copy到Object类型的数组中去 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class);&#125; 方法 新增方法 12345678910111213 public void add(int index, E element) &#123; //确保index的位置没有超出数组的范围 rangeCheckForAdd(index);//保证数组的容量是否足以添加进去元素，并且将modCount的值自增1 ensureCapacityInternal(size + 1); // Increments modCount!! //将index位置后面的数据往后移1位 System.arraycopy(elementData, index, elementData, index + 1, size - index); //将元素放置在index位置上 elementData[index] = element; //数据长度+1 size++; &#125; fail-fast机制在遍历一个集合时，当集合结构被修改，会抛出Concurrent Modification Exception。 fail-fast会在以下两种情况下抛出ConcurrentModificationException （1）单线程环境 集合被创建后，在遍历它的过程中修改了结构。 但是迭代器的remove()方法会让expectModcount和modcount 相等，所以在遍历集合的过程中只能通过迭代器的remove()方法进行删除元素。 （2）多线程环境 当一个线程在遍历这个集合，而另一个线程对这个集合的结构进行了修改。 12345public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity); &#125; private void ensureExplicitCapacity(int minCapacity) &#123; //将修改次数+1 modCount++; // overflow-conscious code //增加数组长度 if (minCapacity - elementData.length &gt; 0) grow(minCapacity); &#125; private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; //新数组长度为原先数组长度的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //若新长度依旧小于minCapacity，则将minCapacity作为新长度 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //新长度大于MAX_ARRAY_SIZE，则将新长度置为最大的int值 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); //将就数组copy到新数组上 // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); //MAX_ARRAY_SIZE的值为Integer.MAX_VALUE - 8 return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; get方法 12345public E get(int index) &#123; //确保index的位置没有超出数组的范围 rangeCheck(index); return elementData(index);&#125; remove方法 1234567891011121314151617 public E remove(int index) &#123; //检查是否数组下标越界 rangeCheck(index);//修改次数+1 modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) //将index位置后面的数组往前移1位 System.arraycopy(elementData, index+1, elementData, index, numMoved); //将size的值-1，并将数组最后一位的数据引用置为null 让GC自动回收未被引用的对象 elementData[--size] = null; // clear to let GC do its work//将被移除的对象返回出去 return oldValue; &#125; 123456789101112131415161718public boolean remove(Object o) &#123; if (o == null) &#123; //若是空对象的话则遍历数组将其移除 for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; //不是空对象则遍历数组，通过equals方法判断对象是否相等，相等则将其移除 for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125; 1234567891011private void fastRemove(int index) &#123; //修改次数+1 modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) //将index位置后面的数组往前移1位 System.arraycopy(elementData, index+1, elementData, index, numMoved); //将size的值-1，并将数组最后一位的数据引用置为null 让GC自动回收未被引用的对象 elementData[--size] = null; // clear to let GC do its work&#125; 12345678910public void clear() &#123; //修改次数+1 modCount++; //将所有的数组引用都置为null 让GC回收 // clear to let GC do its work for (int i = 0; i &lt; size; i++) elementData[i] = null; //数组大小置为0 size = 0;&#125; ​由上面源码可以看出，ArrayList的删除操作本质上都是将数组移位，末尾数组引用置为null，让GC自动回收垃圾对象。 迭代器123456789101112131415161718192021222324252627282930313233343536373839404142private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; public boolean hasNext() &#123; return cursor != size; &#125; @SuppressWarnings(\"unchecked\") public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; &#125; 先是一个Itr的类，实现了迭代器接口。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657private class ListItr extends Itr implements ListIterator&lt;E&gt; &#123; ListItr(int index) &#123; super(); cursor = index; &#125; public boolean hasPrevious() &#123; return cursor != 0; &#125; public int nextIndex() &#123; return cursor; &#125; public int previousIndex() &#123; return cursor - 1; &#125; @SuppressWarnings(\"unchecked\") public E previous() &#123; checkForComodification(); int i = cursor - 1; if (i &lt; 0) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i; return (E) elementData[lastRet = i]; &#125; public void set(E e) &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.set(lastRet, e); &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; public void add(E e) &#123; checkForComodification(); try &#123; int i = cursor; ArrayList.this.add(i, e); cursor = i + 1; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125; 然后通过一个ListItr继承Itr类，并同时实现了ListIterator接口。 参考文章参考文章一","tags":[{"name":"集合源码","slug":"集合源码","permalink":"http://yoursite.com/tags/集合源码/"}]},{"title":"HashMap源码解析","date":"2018-05-13T08:04:04.549Z","path":"2018/05/13/HashMap源码/","text":"HashMap源码1.构造器123456789101112131415161718/**构造器默认两个参数：initialCapacity 哈希表（键值对数组）初始化容量（默认为16,2的4次方 loadFactor 加载因子 （默认为0.75）*/public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; init(); &#125; 2.方法12345678910111213 void addEntry(int hash, K key, V value, int bucketIndex) &#123; //判断是否需要对原先的hash表扩容 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; //对hash表扩容 并将旧hash表的内容放入新hash表中 resize(2 * table.length); //通过hash()方法来获取key的hash值 hash = (null != key) ? hash(key) : 0; //根据hash值重新获取Entry在数组中的index bucketIndex = indexFor(hash, table.length); &#125;//新增一个键值对 在hash表中的bucketIndex位置放入一个Entry createEntry(hash, key, value, bucketIndex); &#125; 12345678910111213void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; //将所有的旧hash表的键值对转换到新hash表上 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125; 123456public void clear() &#123; modCount++; //使用Arrays工具类，将hash表的数据都填充成null Arrays.fill(table, null); size = 0; &#125; 1234567891011121314151617 final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125;//获取key的hash值 int hash = (key == null) ? 0 : hash(key); //遍历在hash表中key的hash值所对应位置的链表 通过key.equasls方法来确定key所对应的键值对 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null; &#125; 1234567891011121314151617181920212223242526 public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; //给hash表扩容，若表为空，则按照初始化时的threshold值创建hash表。 //threshold=capacity * loadFactor //若不为空，则该方法扩容为原来hash表的2倍 inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); //若根据key的hash值计算出的hash表位置已经存在了键值对，则遍历该链表，将新的Entry添加到链表的最后 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125;//将hash表的修改次数+1 为了实现fast-fail机制 modCount++; addEntry(hash, key, value, i); return null; &#125; 1234567891011121314151617181920212223242526272829303132333435363738final Entry&lt;K,V&gt; removeEntryForKey(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); int i = indexFor(hash, table.length); //指向链表当前对象前一个对象的引用 Entry&lt;K,V&gt; prev = table[i]; //指向链表当前对象的引用 Entry&lt;K,V&gt; e = prev; while (e != null) &#123; //遍历链表数据直至找到key对应的Entry //next为指向链表当前数据下一个对象的引用 Entry&lt;K,V&gt; next = e.next; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; //hash表修改次数+1 modCount++; //hash表的大小-1 size--; //此时当前一个链表前一个数据与当前数据为同一个对象，说明hash表当前位置不存在链表， //直接将key所对应hash表当前数据的next引用指向当前数据的下一个对象。（链表的删除思想） if (prev == e) table[i] = next; else //此时说明hash表当前位置存在链表，将前一个数据的next引用指向当前数据的下一个对象 prev.next = next; //这是Entry内部类定义的hook方法，每次删除数据都需要调用一次。 e.recordRemoval(this); return e; &#125; prev = e; e = next; &#125; return e;&#125; hook方法就是钩子方法 3. Entry类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869//静态内部类 实现了Map类的内部接口 用于存储键值对static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash; /** * Creates new entry. */ Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; //复写equals方法 public final boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if (k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2))) &#123; Object v1 = getValue(); Object v2 = e.getValue(); if (v1 == v2 || (v1 != null &amp;&amp; v1.equals(v2))) return true; &#125; return false; &#125; public final int hashCode() &#123; return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue()); &#125; public final String toString() &#123; return getKey() + \"=\" + getValue(); &#125; /** * This method is invoked whenever the value in an entry is * overwritten by an invocation of put(k,v) for a key k that's already * in the HashMap. */ void recordAccess(HashMap&lt;K,V&gt; m) &#123; &#125; /** * This method is invoked whenever the entry is * removed from the table. */ void recordRemoval(HashMap&lt;K,V&gt; m) &#123; &#125; &#125; 4.迭代器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 //通过一个抽象内部类HashIterator实现了Iterator接口 //HashMap提供的key和value迭代器都是通过继承这个HashIterator实现的private abstract class HashIterator&lt;E&gt; implements Iterator&lt;E&gt; &#123; Entry&lt;K,V&gt; next; // next entry to return int expectedModCount; // For fast-fail int index; // current slot Entry&lt;K,V&gt; current; // current entry HashIterator() &#123; expectedModCount = modCount; if (size &gt; 0) &#123; // advance to first entry Entry[] t = table; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null) ; &#125; &#125; public final boolean hasNext() &#123; return next != null; &#125; final Entry&lt;K,V&gt; nextEntry() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); Entry&lt;K,V&gt; e = next; if (e == null) throw new NoSuchElementException(); if ((next = e.next) == null) &#123; Entry[] t = table; //当next为null时说明e是hash表当前index位置的链表的最后一个元素 //通过while语句内的方式实现next往后移位直至不为null的一个元素 while (index &lt; t.length &amp;&amp; (next = t[index++]) == null) ; &#125; current = e; return e; &#125; public void remove() &#123; if (current == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); Object k = current.key; current = null; HashMap.this.removeEntryForKey(k); expectedModCount = modCount; &#125; &#125; 123456789101112131415161718//value迭代器内部类private final class ValueIterator extends HashIterator&lt;V&gt; &#123; public V next() &#123; return nextEntry().value; &#125; &#125;//key迭代器内部类 private final class KeyIterator extends HashIterator&lt;K&gt; &#123; public K next() &#123; return nextEntry().getKey(); &#125; &#125;//Entry迭代器内部类 private final class EntryIterator extends HashIterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public Map.Entry&lt;K,V&gt; next() &#123; return nextEntry(); &#125; &#125; 5.关于hash表的两个问题 如何设计才能使减小hash冲突？ 针对如何获取在hash表中的位置，HashMap中主要通过三个部分来减小散列冲突： 第一部分，首先根据Object.hashcode得到一个散列值，Object.hashCode是一个native方法。一般情况下可以认为是该对象的地址信息散列得到的，也就是相当于是对象的ID，同一个对象有相同的ID。这样得到的散列值还是比较合理的. 12345678910111213141516final int hash(Object k) &#123; int h = hashSeed; //对于String的hashCode需要另外计算 if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). //二次散列 h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 第二部分，桶的数量设计。一般由哈希值得到桶的位置都是将哈希值除以桶的数量得到的余数就是桶的位置。一般来说想要尽可能的减少散列冲突有两类办法，一类是使用素数数量的桶，例如hashTable，一类是使用2的幂次数量的桶，例如hashmap，hashmap使用2的次幂的桶有个好处，就是可以用位运算来算，只要将散列值和桶的数量-1相与就是桶的位置不需要除。这样相对来说速度快一些。hashmap里有个静态方法indexof就是用来做这个的。具体下文会说到。 1234567static int indexFor(int h, int length) &#123; // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\"; //长度为2的幂次的hash表，用位运算来将散列值和桶的数量-1相与 就是数组的index,这样比采用除更快 //比如length是4，那如果h是0-3则返回的值就是0-3，如果是h=4则返回0，h=5则返回1 //length-1是因为数组下标从0开始 return h &amp; (length-1);&#125; 第三部分，hashseed，第二部分中曾经说道通过将哈希值与桶的数量-1相与得到桶的位置。但是这样做有一个小的问题。当哈希值非常大，而桶的数量很小的时候回出现仅仅依靠哈希值的低位来散列的结果。这样即使散列值做的很好耶没有办法得到很好的散列。这时hashseed的作用就体现出来的，hashseed通过右移部分哈希值，然后将其亦或得到的结果进行在进行定位桶的位置。这样做就综合考虑了高位和低位的值。从而减小了散列冲突的可能性。此外由于java的语言特性，对于String的情况其hashseed需要额外设计。 123456789101112131415161718192021222324252627282930313233private static class Holder &#123; /** * Table capacity above which to switch to use alternative hashing. */ static final int ALTERNATIVE_HASHING_THRESHOLD; static &#123; String altThreshold = java.security.AccessController.doPrivileged( new sun.security.action.GetPropertyAction( \"jdk.map.althashing.threshold\")); int threshold; try &#123; threshold = (null != altThreshold) ? Integer.parseInt(altThreshold) : ALTERNATIVE_HASHING_THRESHOLD_DEFAULT; // disable alternative hashing if -1 if (threshold == -1) &#123; threshold = Integer.MAX_VALUE; &#125; if (threshold &lt; 0) &#123; throw new IllegalArgumentException(\"value must be positive integer.\"); &#125; &#125; catch(IllegalArgumentException failed) &#123; throw new Error(\"Illegal value for 'jdk.map.althashing.threshold'\", failed); &#125; ALTERNATIVE_HASHING_THRESHOLD = threshold; &#125; &#125; static final int ALTERNATIVE_HASHING_THRESHOLD_DEFAULT = Integer.MAX_VALUE;但是这个静态类常量也是可以根据虚拟机参数的设定来更改的。这也就是Holder这个类这段静态代码的意义了。可以通过调整虚拟机的参数来设定这个域值。关于Holder类是参考别人的文章来的，说实话我也没有完全搞清楚。 在发生hash冲突时，如何解决？ 在发生hash冲突之后，HashMap采用单向链表方式来存储键值对。在前面介绍的getEntry、put等方法的时候，都有遍历链表。 关于final加上final的仅仅是相当于当前的引用不在改变，但是容器的元素是恶意增删的，元素的内容也是可以改变的。 参考链接参考文章一","tags":[{"name":"集合源码","slug":"集合源码","permalink":"http://yoursite.com/tags/集合源码/"}]}]